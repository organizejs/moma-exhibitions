{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup, Comment\n",
    "from itertools import compress\n",
    "from joblib import Parallel, delayed\n",
    "from ethnicolr import census_ln, pred_census_ln, pred_wiki_name\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import util\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoMA exhibits & Artists Exhibited at the MoMA\n",
    "This script is used to build the database of exhibitions and the database of artists exhibited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Web scraping\n",
    "As of 4/6/18, the MoMA has had 4968 exhibits.\n",
    "\n",
    "This script will create two dataframes and output them as files in the path 'data/':\n",
    "- data/artist.pkl\n",
    "- data/exhibition.pkl\n",
    "\n",
    "The exhibition dataset is a set of all exhibitions that have been hosted by the The Museum of Modern Art, MoMA PS1, or moma.org. Exhibitions can be scraped from urls such as: [https://www.moma.org/calendar/exhibitions/100](https://www.moma.org/calendar/exhibitions/100), where 100 represents the id of some exhibit.\n",
    "\n",
    "The artist dataset is created by compiling all artists across all exhibits and removing any duplication. This set of artists will be different from the dataset of artists in their [collection](https://www.moma.org/collection/) since the MoMA does not have to collect an artist's work in order to have shown them. For each exhibit, i, we scrape data from a url : https://www.moma.org/artists?exhibition_id=i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Getting Race and Gender\n",
    "The second part of this notebook uses the data that was scraped and assigns a race and gender to each artist.\n",
    "\n",
    "### Race Data\n",
    "To get an artist's race, I use a two fold method:\n",
    "\n",
    "__Part One__:\n",
    "\n",
    "First I use the python library: [__ethnicolr__](https://github.com/appeler/ethnicolr), that matches names to race. This python library provides several bi-char (Smith ==> sm, mi, it, th) deep learning models that use an LSTM architecture. The specific model I chose is based on wikipedia data as it uses the most international dataset to train the model. It has a model performance of 80% accuracy and 83% recall.\n",
    "\n",
    "__Part Two__:\n",
    "\n",
    "For the second part, I try to increase the accuraccy specifically on American artists using the data from the [US-Census](https://api.census.gov/data/2010/surname.html).\n",
    "\n",
    "To take a conservative stance, I only reassign artists whose race is predicted to be 'white' from _ethnicolr_. If _ethnicolr_ predicts a non-white race, I keep the race assignment as is. This means that I will end up with an under-estimation of white artists, and an over estimation of non-white artists. \n",
    "\n",
    "The first part is to figure out what part of the artist_name string is the lastname. To do this, I start from the last word of the artist_name, and iteratively check whether or not the word has a match in the lastname_race_df.\n",
    "\n",
    "For example, if we get the name \"Millie Bobby Brown\", \n",
    "1. I will start by checking whether or not 'Brown' maps to some name in the lastname_race_df \n",
    "2. if so, I will assign the artist with a race, otherwise, check to see whether or not 'Bobby' maps to some name in the lastname_race_df\n",
    "3. if so, I will assign the artist with a race, otherwise, check to see whether or not 'Millie' maps to some name in the lastname_race_df\n",
    "4. if so, I will assign the artist with a race, otherwise, we keep the race prediction of _ethnicolr_\n",
    "\n",
    "The race assignment is done by randomly sampling from probabilities provided in the US Census dataset. This will mean that on each run, there is a chance that the race assigned to each artist will be different.\n",
    "\n",
    "For example, if we were to assign the lastname \"Brown\" to a race, we will start by looking for the probability distribution of races. We then randomly sample from this distribution to get our prediction:\n",
    "\n",
    "\n",
    "### Gender Data\n",
    "To get an artist's gender, I used the web service: [__genderize.io__](https://www.genderize.io). This service simply takes in a name and spits out a gender, and the probability of its accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There have been 4968 exhibitions archived on the MoMA's website as of 4/7/2018\n",
    "total_exhibitions = 4968\n",
    "\n",
    "# print progress and errors when scaping data\n",
    "print_progress_and_errors = False\n",
    "\n",
    "# scrape a small set of sample data instead of the full data set that would take several hours\n",
    "pull_sample_data = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions for parsing through scraped strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _strip_html(text):\n",
    "    return re.sub('<[^<]+?>', '', text).strip()\n",
    "\n",
    "def _strip_non_numbers(text):\n",
    "    return re.sub(\"[^0-9]\", \"\", text).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`_parse_exhibit` is used to parse through each exhibit on the MoMA's website. For each exhibit, the function will find key information about the exhibit. This function will also call on the `_parse_exhibit_artists` which will get the list of all artists who participated in the exhibit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_exhibit(exhibit_index, print_progress=True):\n",
    "    \"\"\"\n",
    "    Get the following attributes of the exhibit:\n",
    "    - name of exhibit\n",
    "    - date text of exhibit\n",
    "    - year of exhibit\n",
    "    - which museum (MoMA, MoMA PS1, online...)\n",
    "    - press release text\n",
    "    - list of artists (indexed on artist full name)\n",
    "    \"\"\"\n",
    "\n",
    "    if print_progress == True:\n",
    "        if (exhibit_index % 10) == 0:\n",
    "            print(str(exhibit_index) + ', ', end='')\n",
    "    \n",
    "    try:\n",
    "        page = requests.get(\"https://www.moma.org/calendar/exhibitions/%s\"%(exhibit_index))\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        \n",
    "        # get exhibit title\n",
    "        title = _strip_html(str(soup.find('h1', {'class': 'page-header__title'})))\n",
    "        \n",
    "        # get exhibit year and date_full_text\n",
    "        date_full_text = _strip_html(str(soup.find('h2', {'class': 'page-header__subheading--narrow'})))\n",
    "        year = ''\n",
    "        r = re.findall('.*([1-3][0-9]{3})', date_full_text)\n",
    "        if r:\n",
    "            year = str(r.pop())\n",
    "        else:\n",
    "            year = '-1'\n",
    "        \n",
    "        # get which museum (MoMA, PS1, Online...)\n",
    "        museum = _strip_html(str(soup.find('p', {'class': 'calendar-tile__location--title center'})))\n",
    "        \n",
    "        # get press release\n",
    "        press_release_container = soup.find('div', {'class': 'container-uneven--2 body-copy--simple'})\n",
    "        press_release = \" \".join([str(text) for text in press_release_container.find_all('p')])\n",
    "    \n",
    "        # get artists with _parse_exhibit_artists\n",
    "        exhibit_artists_dict = _parse_exhibit_artists(exhibit_index)\n",
    "        artists = \", \".join(list(exhibit_artists_dict['artist_name']))\n",
    "\n",
    "        return title, year, date_full_text, museum, press_release, artists, exhibit_artists_dict\n",
    "    \n",
    "    except Exception:\n",
    "        if print_progress == True:\n",
    "            print(\"Error[%i], \"%exhibit_index, end='')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `_parse_exhibit_artists` function will parse through each artist in a particular exhibit, and retreive specific information for each artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_exhibit_artists(exhibit_index):\n",
    "    \"\"\"\n",
    "    Get the follow attributes of the artists in an exhibit:\n",
    "    - name of artist\n",
    "    - associated gender & ethnicity\n",
    "    - nationality\n",
    "    - number of exhibitions\n",
    "    - number of \"works online\"\n",
    "    \"\"\"\n",
    "    page = requests.get(\"https://www.moma.org/artists?exhibition_id=%s\"%(exhibit_index))\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    artist_tiles = soup.find(\"div\", {\"class\": \"tile-container\"})\n",
    "    \n",
    "    try:\n",
    "        artist_names = artist_tiles.findAll(\"div\", {\"class\": \"caption--artist__name center balance-text\"})\n",
    "        artist_nationalities_and_dates = artist_tiles.findAll(\"div\", {\"class\": \"caption--artist__date center balance-text\"})\n",
    "        artist_exhibitions_and_work_online = artist_tiles.findAll(\"div\", {\"class\": \"caption--artist__count center\"})\n",
    "\n",
    "        name_arr, nationality_arr, exhibitions_arr, work_online_arr = ([] for i in range(4))\n",
    "        for i in range(len(artist_names)):\n",
    "            # get name\n",
    "            name = _strip_html(str(artist_names[i]))\n",
    "\n",
    "            # get nationality if available, None otherwise\n",
    "            nationality_raw = _strip_html(str(artist_nationalities_and_dates[i])).split(', ')\n",
    "            nationality_filter = [x.isalnum() for x in nationality_raw]\n",
    "            nationality_list = list(compress(nationality_raw, nationality_filter))\n",
    "            nationality = nationality_list[0] if len(nationality_list) > 0 else \"\"\n",
    "\n",
    "            exhibitions_and_work_online_raw = _strip_html(str(artist_exhibitions_and_work_online[i])).split(', ')\n",
    "\n",
    "            exhibitions_filter = [\"exhibition\" in x for x in exhibitions_and_work_online_raw]\n",
    "            exhibitions_list = list(compress(exhibitions_and_work_online_raw, nationality_filter))\n",
    "            exhibitions = _strip_non_numbers(exhibitions_list[0]) if len(exhibitions_list) > 0 else 0\n",
    "\n",
    "            work_online_filter = [\"online\" in x for x in exhibitions_and_work_online_raw]\n",
    "            work_online_list = list(compress(exhibitions_and_work_online_raw, work_online_filter))\n",
    "            work_online = _strip_non_numbers(work_online_list[0]) if len(work_online_list) > 0 else 0\n",
    "\n",
    "            name_arr.append(name)\n",
    "            nationality_arr.append(nationality)\n",
    "            exhibitions_arr.append(exhibitions)\n",
    "            work_online_arr.append(work_online)\n",
    "\n",
    "        return {\n",
    "            'artist_name': name_arr,\n",
    "            'nationality': nationality_arr,\n",
    "            'exhibitions': exhibitions_arr,\n",
    "            'work_online': work_online_arr\n",
    "        }\n",
    "    \n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will loop through exhibit indexes 1 to `total_exhibitions`, running the `_parse_exhibit` and `_parse_exhibit_artists` for each index. \n",
    "\n",
    "WARNING: This function is extremely costly, taking up to 3-4 hours to execute (on a single thread)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 17.17165780067444 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\"\"\" COMPUTATIONALLY EXPENSIVE \"\"\"\n",
    "# build exhibit dataframe\n",
    "start_time = time.time()\n",
    "\n",
    "# using joblib [not fully tested]\n",
    "# exhibits = Parallel(n_jobs=2)(delayed(_parse_exhibit)(j+1) for j in range(50))\n",
    "\n",
    "if pull_sample_data:\n",
    "    exhibits = [_parse_exhibit(j+1, print_progress_and_errors) for j in range(100, 110)]\n",
    "else:\n",
    "    exhibits = [_parse_exhibit(j+1, print_progress_and_errors) for j in range(total_exhibitions - 1)]\n",
    "\n",
    "exhibits = [exhibit for exhibit in exhibits if exhibit is not None]\n",
    "\n",
    "titles = [exhibit[0] for exhibit in exhibits]\n",
    "years = [exhibit[1] for exhibit in exhibits]\n",
    "date_full_text = [exhibit[2] for exhibit in exhibits]\n",
    "museum = [exhibit[3] for exhibit in exhibits]\n",
    "press_release = [exhibit[4] for exhibit in exhibits]\n",
    "artists = [exhibit[5] for exhibit in exhibits]\n",
    "artist_dict = [exhibit[6] for exhibit in exhibits]\n",
    "\n",
    "exhibition_df = pd.DataFrame(data={\n",
    "    'exhibition_title': pd.Series(titles, dtype=str),\n",
    "    'year': pd.Series(years, dtype=int),\n",
    "    'date_full_text': pd.Series(date_full_text, dtype=str),\n",
    "    'artists': pd.Series(artists, dtype=str),\n",
    "    'museum': pd.Series(museum, dtype=str),\n",
    "    'press_release': pd.Series(press_release, dtype=str)\n",
    "})\n",
    "\n",
    "artist_df = pd.DataFrame()\n",
    "for d in artist_dict:\n",
    "    artist_df = artist_df.append(pd.DataFrame(d))\n",
    "artist_df = artist_df.reset_index().drop(\"index\", axis=1)\n",
    "    \n",
    "print()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up `artist_df` and assign a race & gender with probabiliy for each artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split artist name into first_name and last_name\n",
    "# if last name is not there, use first name as last name\n",
    "artist_df['first_name'] = artist_df['artist_name'].apply(lambda x: x.split(' ', 1)[0])\n",
    "artist_df['last_name'] = artist_df['artist_name'].apply(lambda x: x.split(' ', 1)[1] if len(x.split(' ', 1)) > 1 else x.split(' ', 1)[0])\n",
    "\n",
    "# use pred_wiki_ln\n",
    "artist_df = pred_wiki_name(artist_df, lname_col=\"last_name\", fname_col=\"first_name\")\n",
    "\n",
    "# drop pcts and rename race to ethnicity\n",
    "artist_df = artist_df.drop(list(artist_df.columns)[-13:], axis=1)\n",
    "artist_df.rename(index=str, columns={\"race\": \"ethnicity\"}, inplace=True)\n",
    "\n",
    "def generalize_race(text):\n",
    "    if \"EastAsian\" in text:\n",
    "        return \"asian\"\n",
    "    elif \"Indian\" in text:\n",
    "        return \"indian\"\n",
    "    elif \"African\" in text:\n",
    "        return \"black\"\n",
    "    elif \"Hispanic\" in text:\n",
    "        return \"hispanic\"\n",
    "    else:\n",
    "        return \"white\"\n",
    "    \n",
    "artist_df['race'] = artist_df['ethnicity'].apply(generalize_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>exhibitions</th>\n",
       "      <th>nationality</th>\n",
       "      <th>work_online</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Karl Schmidt-Rottluff</td>\n",
       "      <td>44</td>\n",
       "      <td>German</td>\n",
       "      <td>68</td>\n",
       "      <td>Karl</td>\n",
       "      <td>Schmidt-Rottluff</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Germanic</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Richard Serra</td>\n",
       "      <td>58</td>\n",
       "      <td>American</td>\n",
       "      <td>64</td>\n",
       "      <td>Richard</td>\n",
       "      <td>Serra</td>\n",
       "      <td>GreaterEuropean,British</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>David Smith</td>\n",
       "      <td>59</td>\n",
       "      <td>American</td>\n",
       "      <td>21</td>\n",
       "      <td>David</td>\n",
       "      <td>Smith</td>\n",
       "      <td>GreaterEuropean,British</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Nancy Spero</td>\n",
       "      <td>15</td>\n",
       "      <td>American</td>\n",
       "      <td>13</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>Spero</td>\n",
       "      <td>GreaterEuropean,WestEuropean,Hispanic</td>\n",
       "      <td>hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Frank Stella</td>\n",
       "      <td>72</td>\n",
       "      <td>American</td>\n",
       "      <td>156</td>\n",
       "      <td>Frank</td>\n",
       "      <td>Stella</td>\n",
       "      <td>GreaterEuropean,British</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Antoni Tàpies</td>\n",
       "      <td>28</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>33</td>\n",
       "      <td>Antoni</td>\n",
       "      <td>Tàpies</td>\n",
       "      <td>GreaterEuropean,British</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Édouard Vuillard</td>\n",
       "      <td>59</td>\n",
       "      <td>French</td>\n",
       "      <td>39</td>\n",
       "      <td>Édouard</td>\n",
       "      <td>Vuillard</td>\n",
       "      <td>GreaterEuropean,WestEuropean,French</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Andy Warhol</td>\n",
       "      <td>132</td>\n",
       "      <td>American</td>\n",
       "      <td>244</td>\n",
       "      <td>Andy</td>\n",
       "      <td>Warhol</td>\n",
       "      <td>GreaterEuropean,British</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Terry Winters</td>\n",
       "      <td>26</td>\n",
       "      <td>American</td>\n",
       "      <td>132</td>\n",
       "      <td>Terry</td>\n",
       "      <td>Winters</td>\n",
       "      <td>GreaterEuropean,British</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Frank Gohlke</td>\n",
       "      <td>13</td>\n",
       "      <td>American</td>\n",
       "      <td>5</td>\n",
       "      <td>Frank</td>\n",
       "      <td>Gohlke</td>\n",
       "      <td>GreaterEuropean,British</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               artist_name exhibitions nationality work_online first_name  \\\n",
       "237  Karl Schmidt-Rottluff          44      German          68       Karl   \n",
       "238          Richard Serra          58    American          64    Richard   \n",
       "239            David Smith          59    American          21      David   \n",
       "240            Nancy Spero          15    American          13      Nancy   \n",
       "241           Frank Stella          72    American         156      Frank   \n",
       "242          Antoni Tàpies          28     Spanish          33     Antoni   \n",
       "243       Édouard Vuillard          59      French          39    Édouard   \n",
       "244            Andy Warhol         132    American         244       Andy   \n",
       "245          Terry Winters          26    American         132      Terry   \n",
       "246           Frank Gohlke          13    American           5      Frank   \n",
       "\n",
       "            last_name                              ethnicity      race  \n",
       "237  Schmidt-Rottluff  GreaterEuropean,WestEuropean,Germanic     white  \n",
       "238             Serra                GreaterEuropean,British     white  \n",
       "239             Smith                GreaterEuropean,British     white  \n",
       "240             Spero  GreaterEuropean,WestEuropean,Hispanic  hispanic  \n",
       "241            Stella                GreaterEuropean,British     white  \n",
       "242            Tàpies                GreaterEuropean,British     white  \n",
       "243          Vuillard    GreaterEuropean,WestEuropean,French     white  \n",
       "244            Warhol                GreaterEuropean,British     white  \n",
       "245           Winters                GreaterEuropean,British     white  \n",
       "246            Gohlke                GreaterEuropean,British     white  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiata/anaconda3/envs/ml/lib/python3.6/site-packages/pandas/core/indexes/api.py:77: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" COMPUTATIONALLY EXPENSIVE ($)\"\"\"\n",
    "# this operation requires using the genderize.io end point - which costs money...\n",
    "def get_genders(names):\n",
    "    url = \"\"\n",
    "    cnt = 0\n",
    "    if not isinstance(names,list):\n",
    "        names = [names,]\n",
    "\n",
    "    for name in names:\n",
    "        # scrub name\n",
    "        if str(name) == None or str(name) == 'nan':\n",
    "            name = \"Unknown\"\n",
    "        else:\n",
    "            name = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", name).strip()\n",
    "            name = re.sub('[^A-Za-z0-9]+', ' ', name).replace(\"&amp;\", \"\")\n",
    "        \n",
    "        if url == \"\":\n",
    "            url = \"name[0]=\" + name\n",
    "        else:\n",
    "            cnt += 1\n",
    "            url = url + \"&name[\" + str(cnt) + \"]=\" + name\n",
    "\n",
    "    key = \"7dc4df2d75de0a9624773093c6717b50\"\n",
    "    req = requests.get(\"https://api.genderize.io/?\" + url + \"&apikey=\"+key)\n",
    "    results = json.loads(req.text)\n",
    "    \n",
    "    retrn = []\n",
    "    for result in results:\n",
    "        if result[\"gender\"] is not None:\n",
    "            retrn.append((result[\"gender\"], result[\"probability\"]))\n",
    "        else:\n",
    "            retrn.append((u'None',u'0.0'))\n",
    "    return retrn    \n",
    "\n",
    "\n",
    "# batch calls to get_genders() into name groupings of len=10 (to minimize times it needs to hit the endpoint)\n",
    "l = len(artist_df)\n",
    "remainder = l % 10\n",
    "artist_genders = []\n",
    "for i in range(1, math.floor(l/10) + 1):\n",
    "    next_10_artists = artist_df.iloc[int(i*10 - 10):int(i*10), 4] # column index 4 is first_name\n",
    "    artist_genders.extend(get_genders(list(next_10_artists)))\n",
    "    if i == math.floor(l/10):\n",
    "        remaining_artist = artist_df.iloc[int(i*10):int(i*10 + remainder + 1), 4] # column index 4 is first_name\n",
    "        artist_genders.extend(get_genders(list(remaining_artist)))\n",
    "        \n",
    "# save genders/gender_prob as separate dataframe\n",
    "gender_df = pd.DataFrame(artist_genders, columns=[\"gender\", \"gender_prob\"])\n",
    "\n",
    "# attach genders dataframe to artist_df\n",
    "artist_df = pd.concat([artist_df, gender_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df = artist_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df = artist_df.drop(['gender_prob', 'first_name', 'last_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastname</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>mix</th>\n",
       "      <th>aian</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98909</th>\n",
       "      <td>erdrich</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98910</th>\n",
       "      <td>egues</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98911</th>\n",
       "      <td>dotan</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98912</th>\n",
       "      <td>dionizio</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98913</th>\n",
       "      <td>donlea</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lastname  white  asian   mix  aian  black  hispanic\n",
       "98909   erdrich   0.74    0.0  0.05  0.12    0.0      0.09\n",
       "98910     egues   0.06    0.0  0.00  0.00    0.0      0.93\n",
       "98911     dotan   0.88    0.0  0.00  0.00    0.0      0.08\n",
       "98912  dionizio   0.92    0.0  0.00  0.00    0.0      0.07\n",
       "98913    donlea   0.94    0.0  0.00  0.00    0.0      0.06"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastname_race_df = util.get_race_dist_of_lastname()\n",
    "lastname_race_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter on american artists only\n",
    "american_artist_df = artist_df[artist_df['nationality'] == 'American']\n",
    "non_american_artist_df = artist_df[artist_df['nationality'] != 'American']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiata/anaconda3/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "\"\"\" COMPUTATIONALLY EXPENSIVE \"\"\"\n",
    "# create mapping with `lastname_race_df` to find assign a race to each artists\n",
    "american_artist_df['race'] = american_artist_df.apply(lambda row: pd.Series(util.get_race_from_full_name(row['artist_name'], row['race'], lastname_race_df)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df = american_artist_df.append(non_american_artist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df['exhibitions'] = artist_df['exhibitions'].apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df = artist_df.sort_values(by='exhibitions', ascending=False).reset_index().drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_race_and_gender(row):\n",
    "    \"\"\"\n",
    "    manual checked american & non-american artists of years: 1957, 1977, 1997 & 2017\n",
    "    \"\"\"\n",
    "    \n",
    "    white_male_list = [\\\n",
    "        \"sol lewitt\", \"ellsworth kelly\", \"edward ruscha\", \"john marin\", \"philip guston\", \"jonathan borofsky\", \\\n",
    "        \"william brice\", \"robert morris\", \"ben shahn\", \"e. mcknight kauffer\", \"robert andrew parker\", \"jan müller\", \\\n",
    "        \"jules pascin\", \"william t. wiley\", \"mark rothko\", \"varujan boghosian\", \"raoul hague\", \"joseph glasco\", \\\n",
    "        \"robert wilson\", \"garry winogrand\", \"albert alcalay\", \"gandy brodie\", \"frank lloyd wright\", \"raimund abraham\", \\\n",
    "        \"morris graves\", \"christopher wool\", \"merce cunningham\", \"louis michel eilshemius\", \"robert brownjohn\", \\\n",
    "        \"woody vasulka\", \"sam francis\",\"robert indiana\", \"william wegman\", \"gordon matta-clark\", \"mel bochner\", \\\n",
    "        \"willem de kooning\", \"milton avery\", \"felix gonzalez-torres\", \"douglas huebler\", \"r. buckminster fuller\", \\\n",
    "        \"tom wesselmann\", \"terry allen\", \"william bailey\", \"robert mapplethorpe\", \"richard foreman\", \"rafael ferrer\", \\\n",
    "        \"pirkle jones\", \"philippe halsman\", \"peter campus\", \"charles atlas\", \"douglas davis\", \"caldecot chubb\", \\\n",
    "        \"ben schonzeit\", \"jared bark\", \"jerry uelsmann\", \"abraham walkowitz\", \"peter young\", \"roger brown\", \\\n",
    "        \"tim rollins\", \"leon polk smith\", \"david park\", \"charles fahlen\", \"barry le va\", \"ian (hugh guiler) hugo\", \\\n",
    "        \"king vidor\", \"walter lang\", \"walter burley griffin\", \"val telberg\", \"paul taylor\", \"r. crumb\", \"remy charlip\", \\\n",
    "        \"robert breer\", \"bruce graham\", \"busby berkeley\", \"charles gwathmey\", \"charles j. brabin\", \"david levinthal\", \\\n",
    "        \"albert herbert\", \"allan mccollum\", \"eugene masselink\", \"george cukor\", \"willy mucha\", \"théo van rysselberghe\", \\\n",
    "        \"théophile-alexandre steinlen\", \"rené magritte\", \"hans namuth\", \"tom wesselmann\", \"mark di suvero\", \\\n",
    "        \"robert watts\", \"abraham walkowitz\", \"russell lee\", \"robert capa\", \"barry le va\", \"jerry uelsmann\", \\\n",
    "        \"george nelson\", \"joel meyerowitz\", \"william lescaze\", \"francis bruguière\", \"philip evergood\", \"jim shaw\", \\\n",
    "        \"george him\", \"günther förg\", \"rené robert bouché\", \"esteban vicente\", \"peter grippe\", \"mark grotjahn\", \\\n",
    "        \"john hejduk\", \"cornell capa\", \"robert gwathmey\", \"robert heinecken\", \"ed emshwiller\", \"donald sultan\", \\\n",
    "        \"gregory amenoff\", \"nathan george horwitt\", \"maurice sterne\", \"jean charlot\", \"timothy o'sullivan\", \\\n",
    "        \"alton pickens\", \"louis faurer\", \"richard neutra\", \"louis lozowick\", \"alfred leslie\", \"morris louis\", \\\n",
    "        \"kim jones\", \"carleton e. watkins\", \"william vandivert\", \"jules olitski\", \"louis schanker\", \\\n",
    "        \"walter dorwin teague\", \"edward kienholz\", \"nathan lyons\", \"walter robinson\", \"larry poons\", \"john steuart curry\", \\\n",
    "        \"alphonse mucha\", \"robert laurent\", \"bill beckley\", \"alfred eisenstaedt\", \"harwell hamilton harris\", \\\n",
    "        \"thomas wilfred\", \"ron davis\", \"geoffrey hendricks\", \"alain kirili\"]\n",
    "    \n",
    "    white_female_list = [\\\n",
    "        \"helen frankenthaler\", \"lee bontecou\", \"yvonne rainer\", \"imogen cunningham\", \"charmion von wiegand\", \"angelo testa\" \\\n",
    "        \"louise nevelson\", \"adrian piper\", \"elizabeth murray\", \"mona hatoum\", \"lee krasner\", \"lois long\", \\\n",
    "        \"claire (claire mahl) moore\", \"alexis smith\", \"trisha brown\", \"lucinda childs\", \"margaret c. anderson\", \\\n",
    "        \"vera (vera neumann)\", \"susan weil\", \"noémi raymond\", \"pat passlof\", \"jan groover\", \"elaine de kooning\", \\\n",
    "        \"nancy holt\", \"susan weil\", \"wanda gág\", \"elizabeth peyton\", \"judith joy ross\", \"louise dahl-wolfe\", \\\n",
    "        \"jane dickson\"]\n",
    "    \n",
    "    asian_female_list = [\\\n",
    "        \"elizabeth mcfadden\", \"tomiyo sasaki\"]\n",
    "    \n",
    "    asian_male_list = [\\\n",
    "        \"shusaku arakawa\", \"lee ufan\", \"wifredo lam\", \"ai weiwei\", \"chinn yuen-yuei\", \"thomas han\", \\\n",
    "        \"jenova (xinghan) chen\", \"eikoh hosoe\", \"ken domon\", \"lee jong-ok\"]\n",
    "    \n",
    "    black_male_list = [\\\n",
    "        \"david hammons\", \"kingelez\", \"raymond saunders\", \"melvin edwards\", \"sam gilliam\", \"Cameron Rowland\", \\\n",
    "        \"terry adkins\", \"jacob lawrence\", \"gordon parks\"]\n",
    "    \n",
    "    black_female_list = [\\\n",
    "        \"minnie evans\", \"kara walker\", \"xaviera simmons\", \"carrie mae weems\", \"alma woodsey thomas\", \\\n",
    "        \"barbara chase-riboud\"]\n",
    "    \n",
    "    hispanic_female_list = [\\\n",
    "        \"andrea bowers\", \"andrea fraser\"]\n",
    "    \n",
    "    hispanic_male_list = [\\\n",
    "        \"rufino tamayo\"]\n",
    "    \n",
    "    none_list = [\\\n",
    "        \"velox ward\", \"dudley huppler\", \"schilli maier\", \"maxi cohen\", \"richard w. landis\", \"skip blumberg\", \\\n",
    "        \"joel fisher\", \"eve sonneman\", \"mia ferrara\", \"john h. lickert\", \"william c. gannett\", \"robert p. gottlieb\", \\\n",
    "        \"orlando giannini\", \"daniel larossa\", \"alfred w. fielding\", \"arthur a. aykanian\", \"don weinreich\", \\\n",
    "        \"janet stein\", \"eliza montgomery\", \"elizabeth mock\", \"roland baladi\"]\n",
    "    \n",
    "    artist_name = str(row['artist_name'].lower())\n",
    "    if \"nknown\" in artist_name \\\n",
    "        or \"nonymous\" in artist_name \\\n",
    "        or \"rtist\" in artist_name \\\n",
    "        or \"ystem\" in artist_name \\\n",
    "        or \"group\" in artist_name \\\n",
    "        or \"corp\" in artist_name \\\n",
    "        or \", \" in artist_name \\\n",
    "        or \"ssociates\" in artist_name \\\n",
    "        or \"tudio\" in artist_name \\\n",
    "        or \"esearch\" in artist_name \\\n",
    "        or \"imension\" in artist_name \\\n",
    "        or \"skidmore\" in artist_name \\\n",
    "        or \"rchitect\" in artist_name \\\n",
    "        or artist_name in none_list:\n",
    "        return None, None\n",
    "    \n",
    "    if artist_name in white_male_list:\n",
    "        return \"white\", \"male\"\n",
    "    \n",
    "    if artist_name in white_female_list:\n",
    "        return \"white\", \"female\"\n",
    "    \n",
    "    if artist_name in asian_female_list:\n",
    "        return \"asian\", \"female\"\n",
    "    \n",
    "    if artist_name in asian_male_list:\n",
    "        return \"asian\", \"male\"\n",
    "    \n",
    "    if artist_name in black_male_list:\n",
    "        return \"black\", \"male\"\n",
    "    \n",
    "    if artist_name in black_female_list:\n",
    "        return \"black\", \"female\"\n",
    "    \n",
    "    if artist_name in hispanic_female_list:\n",
    "        return \"hispanic\", \"female\"\n",
    "    \n",
    "    if artist_name in hispanic_male_list:\n",
    "        return \"hispanic\", \"male\"\n",
    "    \n",
    "    return row['race'], row['gender']\n",
    "\n",
    "artist_df[['race', 'gender']] = artist_df.apply(lambda x: pd.Series(check_race_and_gender(x)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that dataframes look as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(artist_df.shape)\n",
    "artist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exhibition_df.shape)\n",
    "exhibition_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dataframes as pickled files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artist_df.to_pickle('data/artist_%s.pkl' % str(time.strftime(\"%m%d%Y\")))\n",
    "# exhibition_df.to_pickle('data/exhibition_%s.pkl' % str(time.strftime(\"%m%d%Y\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
